# BudCluster Service

[![License](https://img.shields.io/badge/License-AGPL%203.0-blue.svg)](https://opensource.org/licenses/AGPL-3.0)
[![Python 3.10+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)](https://fastapi.tiangolo.com/)
[![Dapr](https://img.shields.io/badge/Dapr-1.10+-blue.svg)](https://dapr.io/)

A comprehensive cluster lifecycle management service that provisions, manages, and deploys AI/ML models to Kubernetes/OpenShift clusters across multiple cloud providers. Part of the Bud Stack platform.

## ğŸš€ Features

- **Multi-Cloud Support**: Automated provisioning for AWS EKS, Azure AKS, and on-premises OpenShift clusters
- **Infrastructure as Code**: Terraform modules for cloud infrastructure and Ansible playbooks for configuration
- **Model Deployment**: Orchestrates AI/ML model deployments with CPU/CUDA/HPU runtime support
- **Security**: RSA/AES encryption for sensitive credentials and kubeconfigs
- **Hardware Detection**: Automatic node capability detection for optimal model placement
- **Workflow Orchestration**: Long-running operations managed through Dapr workflows
- **Monitoring**: Real-time cluster health monitoring and status tracking

## ğŸ“‹ Table of Contents

- [Architecture](#-architecture)
- [Prerequisites](#-prerequisites)
- [Quick Start](#-quick-start)
- [Development](#-development)
- [API Documentation](#-api-documentation)
- [Deployment](#-deployment)
- [Testing](#-testing)
- [Troubleshooting](#-troubleshooting)

## ğŸ—ï¸ Architecture

### Service Structure

```
budcluster/
â”œâ”€â”€ budcluster/
â”‚   â”œâ”€â”€ cluster_ops/        # Cluster lifecycle management
â”‚   â”‚   â”œâ”€â”€ routes.py       # REST API endpoints
â”‚   â”‚   â”œâ”€â”€ services.py     # Business logic
â”‚   â”‚   â”œâ”€â”€ crud.py         # Database operations
â”‚   â”‚   â”œâ”€â”€ models.py       # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ schemas.py      # Pydantic schemas
â”‚   â”‚   â””â”€â”€ workflows.py    # Dapr workflows
â”‚   â”œâ”€â”€ deployment/         # Model deployment orchestration
â”‚   â”‚   â”œâ”€â”€ routes.py       # Deployment endpoints
â”‚   â”‚   â”œâ”€â”€ services.py     # Deployment logic
â”‚   â”‚   â””â”€â”€ workflows.py    # Deployment workflows
â”‚   â””â”€â”€ common/            # Shared utilities
â”œâ”€â”€ charts/                # Helm charts
â”‚   â”œâ”€â”€ bud_runtime_container/    # Model serving runtime
â”‚   â”œâ”€â”€ nfd/                      # Node Feature Discovery
â”‚   â””â”€â”€ prometheus-stack/         # Metrics collection
â”œâ”€â”€ playbooks/             # Ansible automation
â”‚   â”œâ”€â”€ deploy_runtime.yml
â”‚   â”œâ”€â”€ delete_runtime.yml
â”‚   â””â”€â”€ collect_node_info.yml
â””â”€â”€ terraform/             # Infrastructure modules
    â”œâ”€â”€ modules/
    â”‚   â”œâ”€â”€ aws-eks/
    â”‚   â””â”€â”€ azure-aks/
    â””â”€â”€ environments/
```

### Core Components

- **Cluster Operations**: Manages cluster registration, provisioning, and lifecycle
- **Deployment Engine**: Handles model transfers, runtime creation, and benchmarking
- **Infrastructure Automation**: Terraform for cloud resources, Ansible for configuration
- **Security Layer**: Encryption/decryption of sensitive data using RSA and AES
- **Dapr Integration**: Service mesh capabilities for communication and workflows

### Data Flow

1. **Cluster Registration** â†’ Validate credentials â†’ Encrypt and store
2. **Infrastructure Provisioning** â†’ Terraform plan/apply â†’ Update status
3. **Node Detection** â†’ Deploy collectors â†’ Gather hardware capabilities
4. **Model Deployment** â†’ Transfer model â†’ Create runtime â†’ Run benchmarks
5. **Monitoring** â†’ Health checks â†’ Status updates â†’ Event notifications

## ğŸ“¦ Prerequisites

### Required

- **Python 3.10+
- **Docker** and Docker Compose
- **Git**
- **OpenSSL** (for key generation)

### Optional

- **Terraform/OpenTofu** (for cloud provisioning)
- **Ansible** (for on-premises clusters)
- **kubectl** (for direct cluster access)
- **Helm** (for chart deployment)

## ğŸš€ Quick Start

### 1. Clone and Setup

```bash
# Clone the repository
git clone https://github.com/BudEcosystem/bud-stack.git
cd bud-stack/services/budcluster

# Generate encryption keys (required)
mkdir -p crypto-keys
openssl genpkey -algorithm RSA -pkeyopt rsa_keygen_bits:4096 -out crypto-keys/rsa-private-key.pem
openssl rand -out crypto-keys/symmetric-key-256 32
chmod 644 crypto-keys/*

# Setup environment
cp .env.sample .env
# Edit .env with your configuration
```

### 2. Start Development Environment

```bash
# Start with build
./deploy/start_dev.sh --build

# Or start without rebuild
./deploy/start_dev.sh

# Access the service
# API: http://localhost:9082
# API Docs: http://localhost:9082/docs
```

### 3. Initialize Database

```bash
# Run migrations
alembic upgrade head

# Optional: Initialize with sample data
python scripts/initialize_db.py
```

## ğŸ’» Development

### Environment Variables

Key environment variables in `.env`:

```bash
# Database
DATABASE_URL=postgresql://user:pass@localhost:5432/budcluster

# Redis (Dapr state store)
REDIS_URL=redis://localhost:6379

# Dapr Configuration
DAPR_HTTP_PORT=3510
DAPR_GRPC_PORT=50002
DAPR_API_TOKEN=your-token

# Cloud Credentials (optional)
AWS_ACCESS_KEY_ID=your-key
AWS_SECRET_ACCESS_KEY=your-secret
AZURE_CLIENT_ID=your-client-id
AZURE_CLIENT_SECRET=your-secret
AZURE_TENANT_ID=your-tenant

# Crypto Keys
CRYPTO_PRIVATE_KEY_PATH=crypto-keys/rsa-private-key.pem
CRYPTO_SYMMETRIC_KEY_PATH=crypto-keys/symmetric-key-256
```

### Code Quality

```bash
# Install development dependencies
pip install -r requirements-dev.txt

# Install pre-commit hooks
./scripts/install_hooks.sh

# Linting and formatting
ruff check budcluster/ --fix
ruff format budcluster/

# Type checking
mypy budcluster/

# Run all quality checks
./scripts/lint.sh
```

### Database Operations

```bash
# Create migration
alembic revision --autogenerate -m "Add cluster metadata"

# Apply migrations
alembic upgrade head

# Rollback one revision
alembic downgrade -1
```

## ğŸ“š API Documentation

### Key Endpoints

#### Cluster Management
- `POST /clusters/register` - Register new cluster
- `GET /clusters` - List all clusters
- `GET /clusters/{cluster_id}` - Get cluster details
- `PUT /clusters/{cluster_id}` - Update cluster
- `DELETE /clusters/{cluster_id}` - Delete cluster
- `POST /clusters/{cluster_id}/provision` - Provision infrastructure

#### Deployment Operations
- `POST /deployments/deploy` - Deploy model to cluster
- `GET /deployments/{deployment_id}` - Get deployment status
- `DELETE /deployments/{deployment_id}` - Remove deployment
- `POST /deployments/{deployment_id}/benchmark` - Run benchmarks

#### Hardware Detection
- `POST /clusters/{cluster_id}/collect-node-info` - Deploy node collectors
- `GET /clusters/{cluster_id}/nodes` - Get node capabilities

### Workflow Operations

Long-running operations are handled via Dapr workflows:

```python
# Example: Provision cluster
POST /clusters/{cluster_id}/provision
{
  "provider": "aws",
  "region": "us-west-2",
  "node_count": 3
}
```

## ğŸš€ Deployment

### Docker Deployment

```bash
# Build image
docker build -t budcluster:latest .

# Run with docker-compose
docker-compose up -d
```

### Kubernetes Deployment

```bash
# Deploy with Helm
helm install budcluster ./charts/budcluster/

# Or as part of full stack
cd ../../infra/helm/bud
helm dependency update
helm install bud .
```

## ğŸ§ª Testing

### Unit Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=budcluster --cov-report=html

# Run specific test
pytest tests/test_cluster_ops.py::test_register_cluster
```

### Integration Tests

```bash
# With Dapr sidecar
pytest tests/integration/ --dapr-http-port 3510 --dapr-api-token $DAPR_API_TOKEN
```

### End-to-End Tests

```bash
# Deploy test cluster and model
python tests/e2e/test_full_workflow.py
```

## ğŸ”§ Troubleshooting

### Common Issues

#### Missing Crypto Keys
```bash
# Error: FileNotFoundError: crypto-keys/rsa-private-key.pem
# Solution: Generate keys as shown in Quick Start
```

#### Database Connection Failed
```bash
# Error: sqlalchemy.exc.OperationalError
# Solution: Ensure PostgreSQL is running
docker-compose ps
docker-compose up -d postgres
```

#### Dapr Sidecar Not Ready
```bash
# Error: Connection refused to localhost:3510
# Solution: Wait for Dapr initialization or restart
docker-compose restart budcluster-dapr
```

#### Terraform/Ansible Not Found
```bash
# These are optional for development
# Install if testing cloud provisioning:
pip install ansible
brew install terraform  # or use OpenTofu
```

### Debug Mode

Enable debug logging:
```bash
# In .env
LOG_LEVEL=DEBUG

# Or via environment
export LOG_LEVEL=DEBUG
./deploy/start_dev.sh
```

### Health Checks

```bash
# Service health
curl http://localhost:9082/health

# Dapr health
curl http://localhost:3510/v1.0/healthz

# Database connectivity
curl http://localhost:9082/health/db
```

## ğŸ¤ Contributing

Please see the main [Bud Stack Contributing Guide](../../CONTRIBUTING.md).

### Service-Specific Guidelines

1. Follow existing patterns for new endpoints
2. Add tests for new functionality
3. Update API documentation
4. Test with different cluster types
5. Ensure encryption for sensitive data

## ğŸ“„ License

This project is licensed under the AGPL-3.0 License - see the [LICENSE](../../LICENSE) file for details.

## ğŸ”— Related Documentation

- [Main Bud Stack README](../../README.md)
- [CLAUDE.md Development Guide](./CLAUDE.md)
- [API Documentation](http://localhost:9082/docs) (when running)
- [Helm Charts](./charts/)
- [Terraform Modules](./terraform/modules/)
