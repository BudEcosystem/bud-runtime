# Together AI test configuration
# Demonstrates OpenAI SDK universal compatibility with Together AI models

[gateway]
bind_address = "0.0.0.0:3001"
debug = true

[gateway.authentication]
enabled = false

[gateway.observability]
enabled = false

# === Together AI Models via OpenAI SDK ===
# All these models work with OpenAI SDK through /v1/chat/completions

# Latest Llama models
[models."meta-llama/Llama-3.3-70B-Instruct-Turbo"]
routing = ["together"]
endpoints = ["chat"]

[models."meta-llama/Llama-3.3-70B-Instruct-Turbo".providers.together]
type = "together"
model_name = "meta-llama/Llama-3.3-70B-Instruct-Turbo"
api_key_location = { env = "TOGETHER_API_KEY" }

[models."meta-llama/Llama-3.2-3B-Instruct-Turbo"]
routing = ["together"]
endpoints = ["chat"]

[models."meta-llama/Llama-3.2-3B-Instruct-Turbo".providers.together]
type = "together"
model_name = "meta-llama/Llama-3.2-3B-Instruct-Turbo"
api_key_location = { env = "TOGETHER_API_KEY" }

[models."meta-llama/Llama-3.1-8B-Instruct-Turbo"]
routing = ["together"]
endpoints = ["chat"]

[models."meta-llama/Llama-3.1-8B-Instruct-Turbo".providers.together]
type = "together"
model_name = "meta-llama/Llama-3.1-8B-Instruct-Turbo"
api_key_location = { env = "TOGETHER_API_KEY" }

# Qwen models
[models."Qwen/Qwen2.5-72B-Instruct-Turbo"]
routing = ["together"]
endpoints = ["chat"]

[models."Qwen/Qwen2.5-72B-Instruct-Turbo".providers.together]
type = "together"
model_name = "Qwen/Qwen2.5-72B-Instruct-Turbo"
api_key_location = { env = "TOGETHER_API_KEY" }

# Mistral models
[models."mistralai/Mixtral-8x7B-Instruct-v0.1"]
routing = ["together"]
endpoints = ["chat"]

[models."mistralai/Mixtral-8x7B-Instruct-v0.1".providers.together]
type = "together"
model_name = "mistralai/Mixtral-8x7B-Instruct-v0.1"
api_key_location = { env = "TOGETHER_API_KEY" }

# DeepSeek models
[models."deepseek-ai/deepseek-v2.5"]
routing = ["together"]
endpoints = ["chat"]

[models."deepseek-ai/deepseek-v2.5".providers.together]
type = "together"
model_name = "deepseek-ai/deepseek-v2.5"
api_key_location = { env = "TOGETHER_API_KEY" }

# === Together AI Multimodal Models ===
# Embedding models
[models."together-bge-base"]
routing = ["together"]
endpoints = ["embedding"]

[models."together-bge-base".providers.together]
type = "together"
model_name = "BAAI/bge-base-en-v1.5"
api_key_location = { env = "TOGETHER_API_KEY" }

[models."together-m2-bert"]
routing = ["together"]
endpoints = ["embedding"]

[models."together-m2-bert".providers.together]
type = "together"
model_name = "togethercomputer/m2-bert-80M-8k-retrieval"
api_key_location = { env = "TOGETHER_API_KEY" }

# Image generation models
[models."flux-schnell"]
routing = ["together"]
endpoints = ["image_generation"]

[models."flux-schnell".providers.together]
type = "together"
model_name = "black-forest-labs/FLUX.1-schnell"
api_key_location = { env = "TOGETHER_API_KEY" }

# Text-to-speech models
[models."together-tts"]
routing = ["together"]
endpoints = ["text_to_speech"]

[models."together-tts".providers.together]
type = "together"
model_name = "cartesia/sonic"
api_key_location = { env = "TOGETHER_API_KEY" }

# === Comparison models from other providers ===
# For cross-provider testing

[models."gpt-3.5-turbo"]
routing = ["openai"]
endpoints = ["chat"]

[models."gpt-3.5-turbo".providers.openai]
type = "openai"
model_name = "gpt-3.5-turbo"
api_key_location = { env = "OPENAI_API_KEY" }

[models."claude-3-haiku-20240307"]
routing = ["anthropic"]
endpoints = ["chat"]

[models."claude-3-haiku-20240307".providers.anthropic]
type = "anthropic"
model_name = "claude-3-haiku-20240307"
api_key_location = { env = "ANTHROPIC_API_KEY" }

[models."text-embedding-3-small"]
routing = ["openai"]
endpoints = ["embedding"]

[models."text-embedding-3-small".providers.openai]
type = "openai"
model_name = "text-embedding-3-small"
api_key_location = { env = "OPENAI_API_KEY" }
