"""Add gateway blocking rules table

Revision ID: c220a336acbf
Revises: c82d259d07ce
Create Date: 2025-08-11 07:05:55.783303

"""

from typing import Sequence, Union

import sqlalchemy as sa
from alembic import op
from sqlalchemy.dialects import postgresql


# revision identifiers, used by Alembic.
revision: str = "c220a336acbf"
down_revision: Union[str, None] = "c82d259d07ce"
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table("workflow_steps")
    op.drop_table("workflow_runs")
    op.drop_index("idx_deployment_pricing_created_at", table_name="deployment_pricing")
    op.drop_index(
        "idx_deployment_pricing_current_unique",
        table_name="deployment_pricing",
        postgresql_where="(is_current = true)",
    )
    op.drop_index("idx_deployment_pricing_endpoint_id", table_name="deployment_pricing")
    op.drop_index("idx_deployment_pricing_is_current", table_name="deployment_pricing")
    op.drop_index("idx_endpoint_published_composite", table_name="endpoint")
    op.drop_index("ix_endpoint_is_published", table_name="endpoint")
    op.drop_index("ix_endpoint_is_published_published_date", table_name="endpoint")
    op.alter_column("experiments", "project_id", existing_type=sa.UUID(), nullable=False)
    op.drop_index("idx_model_description_search", table_name="model", postgresql_using="gin")
    op.drop_index("idx_model_modality_gin", table_name="model", postgresql_using="gin")
    op.drop_index("idx_model_name_search", table_name="model", postgresql_using="gin")
    op.drop_index("idx_model_status", table_name="model")
    op.drop_index("idx_model_use_cases_gin", table_name="model", postgresql_using="gin")
    op.alter_column(
        "publication_history",
        "created_at",
        existing_type=postgresql.TIMESTAMP(),
        type_=sa.DateTime(timezone=True),
        existing_nullable=False,
    )
    op.alter_column(
        "publication_history",
        "modified_at",
        existing_type=postgresql.TIMESTAMP(),
        type_=sa.DateTime(timezone=True),
        existing_nullable=False,
    )
    op.drop_index("ix_publication_history_deployment_id", table_name="publication_history")
    op.drop_index("ix_publication_history_performed_at", table_name="publication_history")
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_index("ix_publication_history_performed_at", "publication_history", ["performed_at"], unique=False)
    op.create_index("ix_publication_history_deployment_id", "publication_history", ["deployment_id"], unique=False)
    op.alter_column(
        "publication_history",
        "modified_at",
        existing_type=sa.DateTime(timezone=True),
        type_=postgresql.TIMESTAMP(),
        existing_nullable=False,
    )
    op.alter_column(
        "publication_history",
        "created_at",
        existing_type=sa.DateTime(timezone=True),
        type_=postgresql.TIMESTAMP(),
        existing_nullable=False,
    )
    op.create_index("idx_model_use_cases_gin", "model", ["use_cases"], unique=False, postgresql_using="gin")
    op.create_index("idx_model_status", "model", ["status"], unique=False)
    op.create_index(
        "idx_model_name_search",
        "model",
        [sa.literal_column("to_tsvector('english'::regconfig, name::text)")],
        unique=False,
        postgresql_using="gin",
    )
    op.create_index("idx_model_modality_gin", "model", ["modality"], unique=False, postgresql_using="gin")
    op.create_index(
        "idx_model_description_search",
        "model",
        [sa.literal_column("to_tsvector('english'::regconfig, COALESCE(description, ''::character varying)::text)")],
        unique=False,
        postgresql_using="gin",
    )
    op.alter_column("experiments", "project_id", existing_type=sa.UUID(), nullable=True)
    op.create_index(
        "ix_endpoint_is_published_published_date", "endpoint", ["is_published", "published_date"], unique=False
    )
    op.create_index("ix_endpoint_is_published", "endpoint", ["is_published"], unique=False)
    op.create_index(
        "idx_endpoint_published_composite",
        "endpoint",
        ["is_published", "status", sa.literal_column("published_date DESC")],
        unique=False,
    )
    op.create_index("idx_deployment_pricing_is_current", "deployment_pricing", ["is_current"], unique=False)
    op.create_index("idx_deployment_pricing_endpoint_id", "deployment_pricing", ["endpoint_id"], unique=False)
    op.create_index(
        "idx_deployment_pricing_current_unique",
        "deployment_pricing",
        ["endpoint_id"],
        unique=True,
        postgresql_where="(is_current = true)",
    )
    op.create_index(
        "idx_deployment_pricing_created_at", "deployment_pricing", [sa.literal_column("created_at DESC")], unique=False
    )
    op.create_table(
        "workflow_runs",
        sa.Column(
            "id",
            sa.INTEGER(),
            server_default=sa.text("nextval('workflow_runs_id_seq'::regclass)"),
            autoincrement=True,
            nullable=False,
        ),
        sa.Column("workflow_id", sa.UUID(), autoincrement=False, nullable=False),
        sa.Column("workflow_name", sa.VARCHAR(length=128), autoincrement=False, nullable=False),
        sa.Column("status", sa.VARCHAR(length=20), autoincrement=False, nullable=True),
        sa.Column("input", postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=False),
        sa.Column("output", postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
        sa.Column("error", sa.VARCHAR(length=255), autoincrement=False, nullable=True),
        sa.Column("notification_status", postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
        sa.Column("num_retries", sa.INTEGER(), autoincrement=False, nullable=False),
        sa.Column("max_retries", sa.INTEGER(), autoincrement=False, nullable=False),
        sa.Column(
            "created_at",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("now()"),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column("modified_at", postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
        sa.PrimaryKeyConstraint("id", name="workflow_runs_pkey"),
        sa.UniqueConstraint("workflow_id", name="workflow_runs_workflow_id_key"),
        postgresql_ignore_search_path=False,
    )
    op.create_table(
        "workflow_steps",
        sa.Column("id", sa.INTEGER(), autoincrement=True, nullable=False),
        sa.Column("workflow_id", sa.UUID(), autoincrement=False, nullable=False),
        sa.Column("step_id", sa.VARCHAR(length=128), autoincrement=False, nullable=False),
        sa.Column("status", sa.VARCHAR(length=20), autoincrement=False, nullable=True),
        sa.Column("notification_status", postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
        sa.Column("num_retries", sa.INTEGER(), autoincrement=False, nullable=False),
        sa.Column("max_retries", sa.INTEGER(), autoincrement=False, nullable=False),
        sa.Column(
            "created_at",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("now()"),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column("modified_at", postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
        sa.ForeignKeyConstraint(
            ["workflow_id"], ["workflow_runs.workflow_id"], name="workflow_steps_workflow_id_fkey"
        ),
        sa.PrimaryKeyConstraint("id", name="workflow_steps_pkey"),
    )
    # ### end Alembic commands ###
