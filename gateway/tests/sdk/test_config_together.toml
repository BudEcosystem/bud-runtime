# Together AI test configuration
# Demonstrates OpenAI SDK universal compatibility with Together AI models

[gateway]
bind_address = "0.0.0.0:3001"
debug = true

[gateway.authentication]
enabled = false

[gateway.observability]
enabled = false

# === Together AI Models via OpenAI SDK ===
# All these models work with OpenAI SDK through /v1/chat/completions

# Latest Llama models
[models."meta-llama/Llama-3.3-70B-Instruct-Turbo"]
routing = ["together"]
endpoints = ["chat"]

[models."meta-llama/Llama-3.3-70B-Instruct-Turbo".providers.together]
type = "together"
model_name = "meta-llama/Llama-3.3-70B-Instruct-Turbo"
api_key_location = { env = "TOGETHER_API_KEY" }

[models."meta-llama/Llama-3.2-3B-Instruct-Turbo"]
routing = ["together"]
endpoints = ["chat"]

[models."meta-llama/Llama-3.2-3B-Instruct-Turbo".providers.together]
type = "together"
model_name = "meta-llama/Llama-3.2-3B-Instruct-Turbo"
api_key_location = { env = "TOGETHER_API_KEY" }

[models."meta-llama/Llama-3.1-8B-Instruct-Turbo"]
routing = ["together"]
endpoints = ["chat"]

[models."meta-llama/Llama-3.1-8B-Instruct-Turbo".providers.together]
type = "together"
model_name = "meta-llama/Llama-3.1-8B-Instruct-Turbo"
api_key_location = { env = "TOGETHER_API_KEY" }

# Qwen models
[models."Qwen/Qwen2.5-72B-Instruct-Turbo"]
routing = ["together"]
endpoints = ["chat"]

[models."Qwen/Qwen2.5-72B-Instruct-Turbo".providers.together]
type = "together"
model_name = "Qwen/Qwen2.5-72B-Instruct-Turbo"
api_key_location = { env = "TOGETHER_API_KEY" }

# Mistral models
[models."mistralai/Mixtral-8x7B-Instruct-v0.1"]
routing = ["together"]
endpoints = ["chat"]

[models."mistralai/Mixtral-8x7B-Instruct-v0.1".providers.together]
type = "together"
model_name = "mistralai/Mixtral-8x7B-Instruct-v0.1"
api_key_location = { env = "TOGETHER_API_KEY" }

# DeepSeek models
[models."deepseek-ai/deepseek-v2.5"]
routing = ["together"]
endpoints = ["chat"]

[models."deepseek-ai/deepseek-v2.5".providers.together]
type = "together"
model_name = "deepseek-ai/deepseek-v2.5"
api_key_location = { env = "TOGETHER_API_KEY" }

# === Comparison models from other providers ===
# For cross-provider testing

[models."gpt-3.5-turbo"]
routing = ["openai"]
endpoints = ["chat"]

[models."gpt-3.5-turbo".providers.openai]
type = "openai"
model_name = "gpt-3.5-turbo"
api_key_location = { env = "OPENAI_API_KEY" }

[models."claude-3-haiku-20240307"]
routing = ["anthropic"]
endpoints = ["chat"]

[models."claude-3-haiku-20240307".providers.anthropic]
type = "anthropic"
model_name = "claude-3-haiku-20240307"
api_key_location = { env = "ANTHROPIC_API_KEY" }