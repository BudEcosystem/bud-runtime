# Performance test configuration with authentication disabled

[gateway]
authentication.enabled = false
observability.enabled = false

# Models
[models."gpt-3.5-turbo"]
routing = ["openai"]
endpoints = ["chat"]

[models."gpt-3.5-turbo".providers.openai]
type = "openai"
model_name = "gpt-3.5-turbo"
api_base = "http://localhost:3030/openai/"
api_key_location = "none"

# Functions (for legacy /inference endpoint)
[functions.function1]
type = "chat"

[functions.function1.variants.variant1]
type = "chat_completion"
model = "gpt-3.5-turbo"
max_tokens = 100