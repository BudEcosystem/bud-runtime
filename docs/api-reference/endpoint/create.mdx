---
title: 'POST Endpoints'
description: 'Reference for all POST endpoints in the Bud Runtime API'
---

## Create Completion

Generate text completions using language models.

```http
POST /v1/completions
```

### Request Body

```json
{
  "model": "llama2-7b",
  "prompt": "Once upon a time",
  "max_tokens": 100,
  "temperature": 0.7,
  "top_p": 0.9,
  "frequency_penalty": 0,
  "presence_penalty": 0,
  "stop": ["\n"],
  "stream": false
}
```

### Parameters

| Parameter | Type | Required | Description |
|-----------|------|----------|-------------|
| `model` | string | Yes | Model ID to use |
| `prompt` | string/array | Yes | Input prompt(s) |
| `max_tokens` | integer | No | Maximum tokens to generate (default: 100) |
| `temperature` | float | No | Sampling temperature 0-2 (default: 1) |
| `top_p` | float | No | Nucleus sampling (default: 1) |
| `frequency_penalty` | float | No | Frequency penalty -2 to 2 (default: 0) |
| `presence_penalty` | float | No | Presence penalty -2 to 2 (default: 0) |
| `stop` | array | No | Stop sequences |
| `stream` | boolean | No | Stream response (default: false) |

### Response

```json
{
  "id": "cmpl-12345",
  "object": "text_completion",
  "created": 1234567890,
  "model": "llama2-7b",
  "choices": [
    {
      "text": ", in a land far away, there lived a wise old wizard",
      "index": 0,
      "logprobs": null,
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 5,
    "completion_tokens": 15,
    "total_tokens": 20
  }
}
```

## Create Chat Completion

Generate chat-based completions.

```http
POST /v1/chat/completions
```

### Request Body

```json
{
  "model": "llama2-7b",
  "messages": [
    {
      "role": "system",
      "content": "You are a helpful assistant."
    },
    {
      "role": "user",
      "content": "What is the capital of France?"
    }
  ],
  "max_tokens": 100,
  "temperature": 0.7
}
```

### Parameters

| Parameter | Type | Required | Description |
|-----------|------|----------|-------------|
| `model` | string | Yes | Model ID to use |
| `messages` | array | Yes | Array of message objects |
| `max_tokens` | integer | No | Maximum tokens to generate |
| `temperature` | float | No | Sampling temperature |
| `top_p` | float | No | Nucleus sampling |
| `functions` | array | No | Available functions for model |
| `function_call` | string/object | No | Control function calling |

### Message Format

```json
{
  "role": "system|user|assistant|function",
  "content": "message content",
  "name": "function_name",  // Optional, for function messages
  "function_call": {        // Optional, for assistant messages
    "name": "function_name",
    "arguments": "{ \"arg\": \"value\" }"
  }
}
```

### Response

```json
{
  "id": "chatcmpl-12345",
  "object": "chat.completion",
  "created": 1234567890,
  "model": "llama2-7b",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "The capital of France is Paris."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 25,
    "completion_tokens": 10,
    "total_tokens": 35
  }
}
```

## Create Image

Generate images from text prompts.

```http
POST /v1/images/generations
```

### Request Body

```json
{
  "prompt": "A serene landscape with mountains and a lake at sunset",
  "n": 1,
  "size": "1024x1024",
  "quality": "standard",
  "style": "natural",
  "model": "stable-diffusion-xl"
}
```

### Parameters

| Parameter | Type | Required | Description |
|-----------|------|----------|-------------|
| `prompt` | string | Yes | Text description of image |
| `n` | integer | No | Number of images (1-10, default: 1) |
| `size` | string | No | Image size: `256x256`, `512x512`, `1024x1024` |
| `quality` | string | No | Quality: `standard`, `hd` |
| `style` | string | No | Style: `natural`, `vivid` |
| `model` | string | No | Model to use (default: stable-diffusion-xl) |

### Response

```json
{
  "created": 1234567890,
  "data": [
    {
      "url": "https://storage.your-domain.com/images/img-12345.png",
      "revised_prompt": "A serene landscape featuring majestic mountains reflected in a calm lake during a vibrant sunset"
    }
  ]
}
```

## Create Embeddings

Generate text embeddings.

```http
POST /v1/embeddings
```

### Request Body

```json
{
  "input": "The capital of France is Paris",
  "model": "text-embedding-ada-002",
  "encoding_format": "float"
}
```

### Parameters

| Parameter | Type | Required | Description |
|-----------|------|----------|-------------|
| `input` | string/array | Yes | Text(s) to embed |
| `model` | string | Yes | Model ID for embeddings |
| `encoding_format` | string | No | Format: `float`, `base64` |

### Response

```json
{
  "object": "list",
  "data": [
    {
      "object": "embedding",
      "index": 0,
      "embedding": [0.0023, -0.0092, 0.0156, ...]
    }
  ],
  "model": "text-embedding-ada-002",
  "usage": {
    "prompt_tokens": 8,
    "total_tokens": 8
  }
}
```

## Create Deployment

Deploy a custom model.

```http
POST /v1/deployments
```

### Request Body

```json
{
  "model": "custom-llama-7b",
  "source": {
    "type": "s3",
    "uri": "s3://my-bucket/models/custom-llama-7b"
  },
  "replicas": 2,
  "resources": {
    "gpu": "nvidia-a100",
    "memory": "16Gi"
  },
  "autoscaling": {
    "enabled": true,
    "min_replicas": 1,
    "max_replicas": 5,
    "target_gpu_utilization": 70
  }
}
```

### Response

```json
{
  "id": "dep_12345",
  "object": "deployment",
  "status": "creating",
  "created": 1234567890,
  "model": "custom-llama-7b",
  "endpoint": "https://dep-12345.api.your-domain.com"
}
```

## Create API Key

Generate a new API key.

```http
POST /v1/api-keys
```

### Request Body

```json
{
  "name": "Production Key",
  "permissions": [
    "models:read",
    "completions:write",
    "images:write"
  ],
  "rate_limits": {
    "requests_per_minute": 300,
    "requests_per_hour": 10000
  },
  "expires_at": "2025-12-31T23:59:59Z"
}
```

### Response

```json
{
  "id": "key_12345",
  "object": "api_key",
  "name": "Production Key",
  "key": "sk-abc123xyz789...",  // Only shown once!
  "created": 1234567890,
  "expires_at": "2025-12-31T23:59:59Z"
}
```

## Create Fine-tuning Job

Start a fine-tuning job for a model.

```http
POST /v1/fine-tuning/jobs
```

### Request Body

```json
{
  "training_file": "file-12345",
  "model": "llama2-7b",
  "hyperparameters": {
    "n_epochs": 3,
    "batch_size": 4,
    "learning_rate_multiplier": 0.1
  },
  "suffix": "custom-assistant"
}
```

### Response

```json
{
  "id": "ftjob-12345",
  "object": "fine_tuning.job",
  "model": "llama2-7b",
  "created_at": 1234567890,
  "finished_at": null,
  "fine_tuned_model": null,
  "status": "validating_files",
  "hyperparameters": {
    "n_epochs": 3,
    "batch_size": 4,
    "learning_rate_multiplier": 0.1
  }
}
```

## Upload File

Upload a file for fine-tuning or batch processing.

```http
POST /v1/files
```

### Request

```bash
curl https://api.your-domain.com/v1/files \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -F purpose="fine-tune" \
  -F file="@training_data.jsonl"
```

### Response

```json
{
  "id": "file-12345",
  "object": "file",
  "bytes": 120000,
  "created_at": 1234567890,
  "filename": "training_data.jsonl",
  "purpose": "fine-tune",
  "status": "processed",
  "status_details": null
}
```

## Create Batch

Submit a batch of requests for async processing.

```http
POST /v1/batches
```

### Request Body

```json
{
  "input_file_id": "file-12345",
  "endpoint": "/v1/completions",
  "completion_window": "24h",
  "metadata": {
    "job_id": "batch-job-001",
    "department": "marketing"
  }
}
```

### Response

```json
{
  "id": "batch_12345",
  "object": "batch",
  "endpoint": "/v1/completions",
  "input_file_id": "file-12345",
  "completion_window": "24h",
  "status": "validating",
  "created_at": 1234567890,
  "metadata": {
    "job_id": "batch-job-001",
    "department": "marketing"
  }
}
```

## Streaming Responses

For endpoints that support streaming, set `stream: true`:

```javascript
const response = await fetch('https://api.your-domain.com/v1/completions', {
  method: 'POST',
  headers: {
    'Authorization': 'Bearer YOUR_API_KEY',
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({
    model: 'llama2-7b',
    prompt: 'Tell me a story',
    stream: true
  })
});

const reader = response.body.getReader();
const decoder = new TextDecoder();

while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  
  const chunk = decoder.decode(value);
  const lines = chunk.split('\n');
  
  for (const line of lines) {
    if (line.startsWith('data: ')) {
      const data = line.slice(6);
      if (data === '[DONE]') break;
      
      const parsed = JSON.parse(data);
      console.log(parsed.choices[0].text);
    }
  }
}
```

For DELETE endpoints, see [Delete Endpoints](/api-reference/endpoint/delete).