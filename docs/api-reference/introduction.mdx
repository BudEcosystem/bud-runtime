---
title: 'API Reference'
description: 'Complete API reference for Bud Runtime'
---

## Overview

The Bud Runtime API provides a unified interface for interacting with AI models. Our API is designed to be compatible with OpenAI's API format while offering additional features specific to Bud Runtime.

## Base URL

```
https://api.your-domain.com/v1
```

## Authentication

All API requests require authentication using an API key:

```bash
curl https://api.your-domain.com/v1/models \
  -H "Authorization: Bearer YOUR_API_KEY"
```

### Getting an API Key

1. Log in to the Bud Runtime dashboard
2. Navigate to API Keys section
3. Click "Create New Key"
4. Copy and securely store your key

## Request Format

### Headers

Required headers for all requests:

```http
Authorization: Bearer YOUR_API_KEY
Content-Type: application/json
```

Optional headers:

```http
X-Request-ID: unique-request-id
X-User-ID: user-identifier
```

### Request Body

All POST requests accept JSON payloads:

```json
{
  "model": "llama2-7b",
  "prompt": "Hello, world!",
  "max_tokens": 100,
  "temperature": 0.7
}
```

## Response Format

### Successful Response

```json
{
  "id": "req_12345",
  "object": "text_completion",
  "created": 1234567890,
  "model": "llama2-7b",
  "choices": [
    {
      "text": "Generated text here...",
      "index": 0,
      "logprobs": null,
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 10,
    "completion_tokens": 50,
    "total_tokens": 60
  }
}
```

### Error Response

```json
{
  "error": {
    "message": "Invalid API key provided",
    "type": "invalid_request_error",
    "param": null,
    "code": "invalid_api_key"
  }
}
```

## Rate Limits

API rate limits are enforced per API key:

| Tier | Requests/min | Requests/hour | Tokens/day |
|------|--------------|---------------|------------|
| Free | 20 | 100 | 10,000 |
| Basic | 60 | 1,000 | 100,000 |
| Pro | 300 | 10,000 | 1,000,000 |
| Enterprise | Custom | Custom | Custom |

Rate limit headers in responses:

```http
X-RateLimit-Limit: 60
X-RateLimit-Remaining: 45
X-RateLimit-Reset: 1234567890
```

## Endpoints Overview

### Text Generation

- `POST /v1/completions` - Generate text completions
- `POST /v1/chat/completions` - Chat-based completions
- `POST /v1/embeddings` - Generate text embeddings

### Image Generation

- `POST /v1/images/generations` - Generate images
- `POST /v1/images/edits` - Edit existing images
- `POST /v1/images/variations` - Create image variations

### Model Management

- `GET /v1/models` - List available models
- `GET /v1/models/{model_id}` - Get model details

### Account & Usage

- `GET /v1/usage` - Get usage statistics
- `GET /v1/account` - Get account information

## Common Parameters

### Model Selection

```json
{
  "model": "llama2-7b"  // Required: model identifier
}
```

Available models:
- `llama2-7b` - Llama 2 7B parameters
- `llama2-13b` - Llama 2 13B parameters
- `llama2-70b` - Llama 2 70B parameters
- `stable-diffusion-xl` - SDXL for images
- `custom-model` - Your deployed custom models

### Generation Parameters

```json
{
  "temperature": 0.7,      // Controls randomness (0-2)
  "max_tokens": 100,       // Maximum tokens to generate
  "top_p": 0.9,           // Nucleus sampling
  "frequency_penalty": 0,  // Penalize frequent tokens
  "presence_penalty": 0,   // Penalize present tokens
  "stop": ["\n", "END"]   // Stop sequences
}
```

## Streaming Responses

Enable streaming for real-time token generation:

```json
{
  "model": "llama2-7b",
  "prompt": "Tell me a story",
  "stream": true
}
```

Streaming response format:

```
data: {"id":"1","object":"text_completion","created":1234567890,"choices":[{"text":"Once","index":0,"logprobs":null,"finish_reason":null}]}

data: {"id":"1","object":"text_completion","created":1234567890,"choices":[{"text":" upon","index":0,"logprobs":null,"finish_reason":null}]}

data: [DONE]
```

## Webhooks

Configure webhooks for async processing:

```json
{
  "model": "llama2-70b",
  "prompt": "Complex task...",
  "webhook_url": "https://your-server.com/webhook",
  "webhook_events": ["completed", "failed"]
}
```

## SDK Support

Official SDKs available:

- **Python**: `pip install bud-runtime`
- **JavaScript/TypeScript**: `npm install @budruntime/sdk`
- **Go**: `go get github.com/budecosystem/bud-runtime-go`
- **Java**: Maven/Gradle support

## API Versioning

The API version is included in the URL path:

- Current version: `v1`
- Legacy support: Maintained for 12 months
- Deprecation notices: 6 months in advance

## Error Codes

Common error codes and their meanings:

| Code | Description |
|------|-------------|
| 400 | Bad Request - Invalid parameters |
| 401 | Unauthorized - Invalid API key |
| 403 | Forbidden - Access denied |
| 404 | Not Found - Resource not found |
| 429 | Too Many Requests - Rate limit exceeded |
| 500 | Internal Server Error |
| 503 | Service Unavailable |

## Best Practices

1. **Use appropriate models**: Select models based on your task
2. **Implement retry logic**: Handle transient failures
3. **Monitor usage**: Track your API usage
4. **Cache responses**: When appropriate
5. **Handle errors gracefully**: Implement proper error handling

For detailed endpoint documentation, see:
- [GET Endpoints](/api-reference/endpoint/get)
- [POST Endpoints](/api-reference/endpoint/create)
- [DELETE Endpoints](/api-reference/endpoint/delete)
- [Webhook Configuration](/api-reference/endpoint/webhook)